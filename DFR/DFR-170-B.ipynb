{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8425,
     "status": "ok",
     "timestamp": 1742474956194,
     "user": {
      "displayName": "Josef H",
      "userId": "12501506539789171969"
     },
     "user_tz": -60
    },
    "id": "8b8-EUBs96IX"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib as plt\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "import torch.optim as optim\n",
    "from torchvision.models import efficientnet_b6, EfficientNet_B6_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10226,
     "status": "ok",
     "timestamp": 1742475249301,
     "user": {
      "displayName": "Josef H",
      "userId": "12501506539789171969"
     },
     "user_tz": -60
    },
    "id": "MBUBo4tL96IZ"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_image_path = Path('Train_40_50_60/Train')\n",
    "validation_image_path = Path('Val_456')\n",
    "test_image_path = Path('Final_test_40_50_60/Test_40_50_60')\n",
    "\n",
    "train_dataset = ImageFolder(root=train_image_path, transform=transform)\n",
    "validation_dataset = ImageFolder(root=validation_image_path, transform=transform)\n",
    "test_dataset = ImageFolder(root=test_image_path, transform=transform)\n",
    "\n",
    "BS = 4 \n",
    "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BS, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1742475291095,
     "user": {
      "displayName": "Josef H",
      "userId": "12501506539789171969"
     },
     "user_tz": -60
    },
    "id": "I1_rMEDU96Ia"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import efficientnet_b6, EfficientNet_B6_Weights\n",
    "\n",
    "class efficientnet_feature_extractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = efficientnet_b6(weights=EfficientNet_B6_Weights.DEFAULT)\n",
    "        self.model.eval()\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        def get_features(module, input, output):\n",
    "            self.features.append(output)\n",
    "        self.model.features[1].register_forward_hook(get_features)\n",
    "        self.model.features[2][-1].register_forward_hook(get_features)\n",
    "        self.model.features[3][-1].register_forward_hook(get_features)\n",
    "        self.model.features[4][-1].register_forward_hook(get_features)\n",
    "        self.model.features[5][-1].register_forward_hook(get_features)\n",
    "        self.model.features[6][-1].register_forward_hook(get_features)\n",
    "        \n",
    "        self.pool = nn.AvgPool2d(kernel_size=3, stride=3)\n",
    "        self.input_size = 512\n",
    "        self.final_size = 170   \n",
    "    def forward(self, input):\n",
    "        self.features = [] \n",
    "        with torch.no_grad():\n",
    "            _ = self.model(input)\n",
    "        self.feature_maps = self.features\n",
    "        agg_features = []\n",
    "        for fmap in self.features:\n",
    "            fmap_up = F.interpolate(fmap, size=(self.input_size, self.input_size),\n",
    "                                    mode='bilinear', align_corners=False)\n",
    "            fmap_agg = self.pool(fmap_up)\n",
    "            agg_features.append(fmap_agg)\n",
    "        merged = torch.cat(agg_features, dim=1)\n",
    "        return merged \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    extractor = efficientnet_feature_extractor()\n",
    "    x = torch.randn(1, 3, 512, 512)\n",
    "    out = extractor(x)\n",
    "    print(\"Output:\", out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "from torchvision.models import efficientnet_b6, EfficientNet_B6_Weights\n",
    "\n",
    "class efficientnet_feature_extractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        weights = EfficientNet_B6_Weights.DEFAULT\n",
    "        self.preprocess = weights.transforms()      \n",
    "        self.model = efficientnet_b6(weights=weights)\n",
    "        self.model.eval()\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        def get_features(module, input, output):\n",
    "            self.features.append(output)\n",
    "        for idx in range(1, 7):\n",
    "            self.model.features[idx][-1].register_forward_hook(get_features)\n",
    "\n",
    "        self.input_size = 512\n",
    "        self.pool = nn.AvgPool2d(kernel_size=3, stride=3)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.features = []\n",
    "        with torch.no_grad():\n",
    "            _ = self.model(input)\n",
    "        agg = []\n",
    "        for fmap in self.features:\n",
    "            fmap_up = F.interpolate(fmap,\n",
    "                                    size=(self.input_size, self.input_size),\n",
    "                                    mode='bilinear')\n",
    "            fmap_agg = self.pool(fmap_up)\n",
    "            agg.append(fmap_agg)\n",
    "        return torch.cat(agg, dim=1)\n",
    "\n",
    "def compute_latent_dim(feature_matrix, threshold=0.90):\n",
    "    pca = PCA(n_components=feature_matrix.shape[1])\n",
    "    pca.fit(feature_matrix)\n",
    "    cumvar = np.cumsum(pca.explained_variance_ratio_)\n",
    "    return int(np.argmax(cumvar >= threshold) + 1)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    feat_ext = efficientnet_feature_extractor()\n",
    "    feat_ext.eval()\n",
    "\n",
    "    image_folder = 'Train_40_50_60/Train/Train_40_50_60'\n",
    "    image_paths = [os.path.join(image_folder, fn) for fn in os.listdir(image_folder)][:30]\n",
    "\n",
    "    feats_list = []\n",
    "    with torch.no_grad():\n",
    "        for p in image_paths:\n",
    "            img = Image.open(p).convert('RGB')\n",
    "            inp = feat_ext.preprocess(img).unsqueeze(0)  \n",
    "            fmap = feat_ext(inp)                        \n",
    "            arr = (fmap.cpu()\n",
    "                       .numpy()\n",
    "                       .transpose(0,2,3,1)\n",
    "                       .reshape(-1, fmap.size(1)))   \n",
    "            feats_list.append(arr)\n",
    "\n",
    "    X = np.vstack(feats_list)\n",
    "    print(\"Running PCA on feature matrix of shape:\", X.shape)\n",
    "    latent_dim = compute_latent_dim(X, threshold=0.90)\n",
    "    print(\"â†’ Selected latent_dim =\", latent_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1742475320670,
     "user": {
      "displayName": "Josef H",
      "userId": "12501506539789171969"
     },
     "user_tz": -60
    },
    "id": "O0lq9ssM96Ic"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DFR_FeatureCAE(nn.Module):\n",
    "    def __init__(self, in_channels=832, latent_dim=260, is_bn=True):\n",
    "        super(DFR_FeatureCAE, self).__init__()\n",
    "        # --- Encoder ---\n",
    "        mid1 = (in_channels + 2 * latent_dim) // 2\n",
    "        enc_layers = []\n",
    "        enc_layers.append(nn.Conv2d(in_channels, mid1, kernel_size=1, stride=1, padding=0))\n",
    "        if is_bn:\n",
    "            enc_layers.append(nn.BatchNorm2d(mid1))\n",
    "        enc_layers.append(nn.ReLU())\n",
    "        \n",
    "        enc_layers.append(nn.Conv2d(mid1, 2 * latent_dim, kernel_size=1, stride=1, padding=0))\n",
    "        if is_bn:\n",
    "            enc_layers.append(nn.BatchNorm2d(2 * latent_dim))\n",
    "        enc_layers.append(nn.ReLU())\n",
    "        \n",
    "        enc_layers.append(nn.Conv2d(2 * latent_dim, latent_dim, kernel_size=1, stride=1, padding=0))\n",
    "        self.encoder = nn.Sequential(*enc_layers)\n",
    "        \n",
    "        # --- Decoder ---\n",
    "        dec_layers = []\n",
    "\n",
    "        dec_layers.append(nn.Conv2d(latent_dim, 2 * latent_dim, kernel_size=1, stride=1, padding=0))\n",
    "        if is_bn:\n",
    "            dec_layers.append(nn.BatchNorm2d(2 * latent_dim))\n",
    "        dec_layers.append(nn.ReLU())\n",
    "        \n",
    "        dec_layers.append(nn.Conv2d(2 * latent_dim, mid1, kernel_size=1, stride=1, padding=0))\n",
    "        if is_bn:\n",
    "            dec_layers.append(nn.BatchNorm2d(mid1))\n",
    "        dec_layers.append(nn.ReLU())\n",
    "        \n",
    "        dec_layers.append(nn.Conv2d(mid1, in_channels, kernel_size=1, stride=1, padding=0))\n",
    "        self.decoder = nn.Sequential(*dec_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        recon = self.decoder(latent)\n",
    "        return recon\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cae = DFR_FeatureCAE(in_channels=832, latent_dim=260, is_bn=True)\n",
    "    x = torch.randn(4, 832, 170, 170)\n",
    "    recon = cae(x)\n",
    "    loss = nn.MSELoss()(recon, x)\n",
    "    print(\"Reconstruction Loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1742475322291,
     "user": {
      "displayName": "Josef H",
      "userId": "12501506539789171969"
     },
     "user_tz": -60
    },
    "id": "N2tLd20S96Ic"
   },
   "outputs": [],
   "source": [
    "model = DFR_FeatureCAE(in_channels=832, latent_dim=260, is_bn=True).cuda()\n",
    "backbone = efficientnet_feature_extractor()\n",
    "backbone.cuda()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = []\n",
    "Validation_Loss = []\n",
    "\n",
    "BS = 4\n",
    "num_epochs = 150\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    for data,_ in train_loader:\n",
    "        with torch.no_grad():\n",
    "            features = backbone(data.cuda())\n",
    "        # Forward pass\n",
    "        output = model(features)\n",
    "        # Compute the loss\n",
    "        loss = criterion(output, features)\n",
    "        # Backpropagation and optimization step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    Loss.append(loss.item())\n",
    "\n",
    "    # Calculate validation loss\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss_sum = 0.0\n",
    "        num_batches = 0\n",
    "        for data, _ in test_loader:\n",
    "            features = backbone(data.cuda())\n",
    "            output = model(features)\n",
    "            val_loss = criterion(output, features)\n",
    "            val_loss_sum += val_loss.item()\n",
    "            num_batches += 1\n",
    "        val_loss_avg = val_loss_sum / num_batches\n",
    "        Validation_Loss.append(val_loss_avg)\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item(), val_loss_avg))\n",
    "\n",
    "plt.plot(Loss, label='Training Loss')\n",
    "plt.plot(Validation_Loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "if len(Loss) >= 5:\n",
    "    safe_train_loss = min(Loss[-5:])\n",
    "else:\n",
    "    safe_train_loss = min(Loss)\n",
    "print(f\"Safe Training Loss (min of last 5 epochs): {safe_train_loss:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), 'Eff_transform_40_60-170-1-6_avg_832-260.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vHTEfnwS96Ie"
   },
   "outputs": [],
   "source": [
    "def decision_function(segm_map):\n",
    "\n",
    "    mean_top_k_values = []\n",
    "\n",
    "    for map in segm_map:\n",
    "        flattened_tensor = map.reshape(-1)\n",
    "        sorted_tensor, _ = torch.sort(flattened_tensor,descending=True)\n",
    "        mean_top_k_value = sorted_tensor[:20].mean()\n",
    "\n",
    "        mean_top_k_values.append(mean_top_k_value)\n",
    "\n",
    "    return torch.stack(mean_top_k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=[]\n",
    "y_pred=[]\n",
    "y_score=[]\n",
    "\n",
    "model.eval()\n",
    "backbone.eval()\n",
    "\n",
    "test_path = Path('Final_test_40_50_60/Test_40_50_60')\n",
    "\n",
    "for path in test_path.glob('*/*.jpeg'):\n",
    "    fault_type = path.parts[-2]\n",
    "    test_image = transform(Image.open(path)).cuda().unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = backbone(test_image)\n",
    "        recon = model(features)\n",
    "    \n",
    "    segm_map = ((features - recon)**2).mean(axis=(1))[:,20:-20,20:-20]\n",
    "    y_score_image = decision_function(segm_map=segm_map)\n",
    "    best_threshold = 0.1\n",
    "    y_pred_image = 1*(y_score_image >= best_threshold)\n",
    "    \n",
    "    y_true_image = 0 if fault_type == 'OK' else 1\n",
    "    \n",
    "    y_true.append(y_true_image)\n",
    "    y_pred.append(y_pred_image.cpu().numpy())\n",
    "    y_score.append(y_score_image.cpu().numpy())\n",
    "    \n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "y_score = np.array(y_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 939
    },
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1742413576943,
     "user": {
      "displayName": "Josef H",
      "userId": "12501506539789171969"
     },
     "user_tz": -60
    },
    "id": "o5uac-Ho96Ie",
    "outputId": "7b88f89a-a1fb-4f74-97f5-e28536b65a10"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix,ConfusionMatrixDisplay, f1_score, accuracy_score, precision_score, recall_score\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "auc_roc_score = roc_auc_score(y_true, y_score)\n",
    "print(\"AUC-ROC Score:\", auc_roc_score)\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc_roc_score)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "f1_scores = [f1_score(y_true, y_score >= threshold) for threshold in thresholds]\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "print('Threshold: ',best_threshold)\n",
    "y_pred = (y_score >= best_threshold).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_true, (y_score >= best_threshold).astype(int))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['OK','NOK'])\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "pre = precision_score(y_true, y_pred, zero_division=0)\n",
    "rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {pre:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, roc_curve\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "\n",
    "image_folder = \"Final_test_40_50_60/Test_40_50_60/NOK\"\n",
    "mask_folder = \"Masks_40_50_60/Masks_40_50_60\"\n",
    "resize_to = (512, 512)\n",
    "crop_border = 0\n",
    "\n",
    "all_image_paths = sorted(glob.glob(os.path.join(image_folder, \"*.jpeg\")))\n",
    "valid_paths = [p for p in all_image_paths if os.path.exists(os.path.join(mask_folder, os.path.splitext(os.path.basename(p))[0] + \".png\"))]\n",
    "selected_paths = random.sample(valid_paths, 250)\n",
    "\n",
    "transform_img = transforms.Compose([\n",
    "    transforms.Resize(resize_to),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "transform_mask = transforms.Compose([\n",
    "    transforms.Resize(resize_to, interpolation=InterpolationMode.NEAREST),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()\n",
    "backbone.eval()\n",
    "\n",
    "all_scores = []\n",
    "all_gts = []\n",
    "error_maps = []\n",
    "\n",
    "for path in selected_paths:\n",
    "    base = os.path.splitext(os.path.basename(path))[0]\n",
    "    mask_path = os.path.join(mask_folder, f\"{base}.png\")\n",
    "\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "    img_tensor = transform_img(img).unsqueeze(0).to(device)\n",
    "    mask_tensor = transform_mask(mask).squeeze(0).numpy()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = backbone(img_tensor)\n",
    "        recon = model(features)\n",
    "\n",
    "        if isinstance(recon, tuple):\n",
    "            recon = recon[0]\n",
    "\n",
    "        err_map = ((features - recon) ** 2).mean(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "\n",
    "    err_map_up = cv2.resize(err_map, resize_to, interpolation=cv2.INTER_LINEAR)\n",
    "    if crop_border > 0:\n",
    "        err_map_up = err_map_up[crop_border:-crop_border, crop_border:-crop_border]\n",
    "        mask_tensor = mask_tensor[crop_border:-crop_border, crop_border:-crop_border]\n",
    "\n",
    " \n",
    "    norm_err = (err_map_up - err_map_up.min()) / (err_map_up.max() - err_map_up.min() + 1e-8)\n",
    "    all_scores.extend(norm_err.flatten())\n",
    "    all_gts.extend((mask_tensor > 0.5).astype(np.uint8).flatten())\n",
    "    error_maps.append(norm_err)\n",
    "\n",
    "\n",
    "all_scores = np.array(all_scores)\n",
    "all_gts = np.array(all_gts)\n",
    "\n",
    "\n",
    "thresholds = np.linspace(0, 1, 200)\n",
    "f1s = [f1_score(all_gts, all_scores >= t) for t in thresholds]\n",
    "best_threshold = thresholds[np.argmax(f1s)]\n",
    "print(f\"Best threshold (by F1): {best_threshold:.4f}\")\n",
    "\n",
    "\n",
    "fpr, tpr, _ = roc_curve(all_gts, all_scores)\n",
    "auc = roc_auc_score(all_gts, all_scores)\n",
    "print(f\"AUROC:{auc}\")\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(fpr, tpr, label=f\"AUROC = {auc:.3f}\")\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Pixel-wise ROC Curve (Features AE)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNdtIAJV4atk5zlkeHnfHym",
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
