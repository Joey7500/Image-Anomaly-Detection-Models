{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8425,
     "status": "ok",
     "timestamp": 1742474956194,
     "user": {
      "displayName": "Josef H",
      "userId": "12501506539789171969"
     },
     "user_tz": -60
    },
    "id": "8b8-EUBs96IX"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_image_path = Path('Train_plain_010')\n",
    "validation_image_path = Path('Val_010')\n",
    "test_image_path = Path('Final_test_0_10/Test_0_10')\n",
    "\n",
    "train_dataset = ImageFolder(root=train_image_path, transform=transform)\n",
    "validation_dataset = ImageFolder(root=validation_image_path, transform=transform)\n",
    "test_dataset = ImageFolder(root=test_image_path, transform=transform)\n",
    "\n",
    "BS = 16 \n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BS, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10226,
     "status": "ok",
     "timestamp": 1742475249301,
     "user": {
      "displayName": "Josef H",
      "userId": "12501506539789171969"
     },
     "user_tz": -60
    },
    "id": "MBUBo4tL96IZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# CBAM modules unchanged\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        mid = max(1, channels // reduction)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(channels, mid, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid, channels, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        a1 = self.fc(self.avg_pool(x))\n",
    "        a2 = self.fc(self.max_pool(x))\n",
    "        return x * self.sigmoid(a1 + a2)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        padding = kernel_size // 2\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mx, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        av = torch.mean(x, dim=1, keepdim=True)\n",
    "        m = torch.cat([mx, av], dim=1)\n",
    "        return x * self.sigmoid(self.conv(m))\n",
    "\n",
    "class CBAMResBlock(nn.Module):\n",
    "    def __init__(self, channels, dropout=0.2, use_residual=True):\n",
    "        super().__init__()\n",
    "        self.use_residual = use_residual\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(channels)\n",
    "        self.ca    = ChannelAttention(channels)\n",
    "        self.sa    = SpatialAttention()\n",
    "        self.dropout = nn.Dropout2d(dropout)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x if self.use_residual else torch.zeros_like(x)\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(out)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.ca(out)\n",
    "        out = self.sa(out)\n",
    "        if self.use_residual:\n",
    "            out = out + residual\n",
    "        return self.relu(out)\n",
    "\n",
    "class RevisedAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_channels=128):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 4, 2, 1), nn.BatchNorm2d(32), nn.ReLU(inplace=True)\n",
    "        )  # [B,32,256,256]\n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(inplace=True)\n",
    "        )  # [B,64,128,128]\n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(inplace=True)\n",
    "        )  # [B,128,64,64]\n",
    "        self.enc4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(inplace=True)\n",
    "        )  # [B,256,32,32]\n",
    "\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(256, latent_channels, 1),\n",
    "            nn.BatchNorm2d(latent_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ) \n",
    "\n",
    "        # Decoder\n",
    "        self.dec1_conv = nn.ConvTranspose2d(latent_channels, 128, 4, 2, 1) \n",
    "        self.dec1_cbam = CBAMResBlock(128 + 128, dropout=0.2, use_residual=False)\n",
    "        self.dec1_bn   = nn.BatchNorm2d(128)\n",
    "\n",
    "\n",
    "        self.dec2_conv = nn.ConvTranspose2d(128, 64, 4, 2, 1)  # [B,64,128,128]\n",
    "        self.dec2_cbam = CBAMResBlock(64, dropout=0.2, use_residual=False)\n",
    "        self.dec2_bn   = nn.BatchNorm2d(64)\n",
    "\n",
    "   \n",
    "        self.dec3_conv = nn.ConvTranspose2d(64, 32, 4, 2, 1)  # [B,32,256,256]\n",
    "        self.dec3_cbam = CBAMResBlock(32, dropout=0.2, use_residual=False)\n",
    "        self.dec3_bn   = nn.BatchNorm2d(32)\n",
    "\n",
    "\n",
    "        self.dec4_conv = nn.ConvTranspose2d(32, 16, 4, 2, 1)  # [B,16,512,512]\n",
    "        self.dec4_cbam = CBAMResBlock(16, dropout=0.2, use_residual=False)\n",
    "        self.dec4_bn   = nn.BatchNorm2d(16)\n",
    "\n",
    "        # Output\n",
    "        self.out_conv = nn.Conv2d(16, 3, 3, 1, 1)\n",
    "        self.out_act  = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.enc1(x)\n",
    "        x2 = self.enc2(x1)\n",
    "        x3 = self.enc3(x2)\n",
    "        x4 = self.enc4(x3)\n",
    "\n",
    "        # Bottleneck\n",
    "        z  = self.bottleneck(x4)\n",
    "\n",
    "        d1 = self.dec1_conv(z)\n",
    "        d1 = torch.cat([d1, x3], dim=1)\n",
    "        d1 = self.dec1_cbam(d1)\n",
    "        d1 = self.dec1_bn(d1[:, :128, :, :])\n",
    "\n",
    "        d2 = self.dec2_conv(d1)\n",
    "        d2 = self.dec2_cbam(d2)\n",
    "        d2 = self.dec2_bn(d2)\n",
    "\n",
    "        d3 = self.dec3_conv(d2)\n",
    "        d3 = self.dec3_cbam(d3)\n",
    "        d3 = self.dec3_bn(d3)\n",
    "\n",
    "        d4 = self.dec4_conv(d3)\n",
    "        d4 = self.dec4_cbam(d4)\n",
    "        d4 = self.dec4_bn(d4)\n",
    "\n",
    "        out = self.out_conv(d4)\n",
    "        return self.out_act(out), z\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = RevisedAutoencoder(latent_channels=128).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1742475291095,
     "user": {
      "displayName": "Josef H",
      "userId": "12501506539789171969"
     },
     "user_tz": -60
    },
    "id": "I1_rMEDU96Ia"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "window_size = 7\n",
    "sigma = 1.5\n",
    "\n",
    "coords = torch.arange(window_size).float() - window_size//2\n",
    "gaussian_kernel = torch.exp(-(coords**2).unsqueeze(0) - (coords**2).unsqueeze(1) / (2*(sigma**2)))\n",
    "gaussian_kernel = gaussian_kernel / gaussian_kernel.sum()\n",
    "gaussian_kernel = gaussian_kernel.view(1, 1, window_size, window_size)\n",
    "def ssim_loss(img, recon):\n",
    "    C = img.shape[1]\n",
    "    window = gaussian_kernel.to(img.device, img.dtype).repeat(C, 1, 1, 1)\n",
    "\n",
    "    mu_img = F.conv2d(img, window, padding=window_size//2, groups=C)\n",
    "    mu_rec = F.conv2d(recon, window, padding=window_size//2, groups=C)\n",
    "    \n",
    "    mu_img_sq = mu_img * mu_img\n",
    "    mu_rec_sq = mu_rec * mu_rec\n",
    "    mu_img_rec = mu_img * mu_rec\n",
    "    sigma_img = F.conv2d(img * img, window, padding=window_size//2, groups=C) - mu_img_sq\n",
    "    sigma_rec = F.conv2d(recon * recon, window, padding=window_size//2, groups=C) - mu_rec_sq\n",
    "    sigma_img_rec = F.conv2d(img * recon, window, padding=window_size//2, groups=C) - mu_img_rec\n",
    "    C1 = (0.01 ** 2)\n",
    "    C2 = (0.03 ** 2)\n",
    "    \n",
    "    ssim_n = (2 * mu_img_rec + C1) * (2 * sigma_img_rec + C2)\n",
    "    ssim_d = (mu_img_sq + mu_rec_sq + C1) * (sigma_img + sigma_rec + C2)\n",
    "    ssim_map = ssim_n / (ssim_d + 1e-8)\n",
    "    loss = torch.clamp((1 - ssim_map) / 2, min=0, max=1)\n",
    "    return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "num_epochs = 25\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for images, _ in train_loader: \n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        recon, z = model(images)\n",
    "        loss_mse = mse_loss_fn(recon, images)\n",
    "        loss_ssim = ssim_loss(images, recon)\n",
    "        loss = 0.15*loss_mse + 0.85*loss_ssim\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        \n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch}/{num_epochs} - Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"AE_0_10_plain_revisedmmm.pth\")\n",
    "print(\"Model weights saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def decision_function(segm_map):\n",
    "    scores = []\n",
    "    for i in range(segm_map.size(0)):\n",
    "        vals, _ = torch.topk(segm_map[i].flatten(), k=1500)\n",
    "        scores.append(vals.mean())\n",
    "    return torch.stack(scores)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_score = []\n",
    "error_map_min, error_map_max = float('inf'), -float('inf')\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        recon,_ = model(images)\n",
    "        err_map = ((images - recon) ** 2).mean(dim=1)  \n",
    "        err_map_cropped = err_map\n",
    "        scores = decision_function(err_map_cropped)\n",
    "        y_true.extend(labels.cpu().tolist())\n",
    "        y_score.extend(scores.cpu().tolist())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "y_score = np.array(y_score)\n",
    "\n",
    "\n",
    "auc = roc_auc_score(y_true, y_score)\n",
    "print(f\"AUC-ROC Score: {auc:.4f}\")\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='orange', label=f'ROC curve (AUC = {auc:.2f})')\n",
    "plt.plot([0,1],[0,1],'--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "f1_scores = [f1_score(y_true, y_score >= threshold) for threshold in thresholds]\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "\n",
    "print(f\"Best Threshold (by F1): {best_threshold:.8f}\")\n",
    "\n",
    "\n",
    "y_pred = (y_score >= best_threshold).astype(int)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['OK','NOK'])\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "pre = precision_score(y_true, y_pred, zero_division=0)\n",
    "rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {pre:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, jaccard_score, roc_curve\n",
    "\n",
    "image_folder = \"Final_test_0_10/Test_0_10/NOK\"\n",
    "mask_folder = \"Masks_010/Pixel_masks_010\"\n",
    "resize_to = (512, 512)\n",
    "\n",
    "all_image_paths = sorted(glob.glob(os.path.join(image_folder, \"*.jpeg\")))\n",
    "valid_paths = [p for p in all_image_paths if os.path.exists(os.path.join(mask_folder, os.path.splitext(os.path.basename(p))[0] + \".png\"))]\n",
    "selected_paths = random.sample(valid_paths, 50)\n",
    "\n",
    "orig_images, gt_masks = [], []\n",
    "for path in selected_paths:\n",
    "    base = os.path.splitext(os.path.basename(path))[0]\n",
    "    mask_path = os.path.join(mask_folder, f\"{base}.png\")\n",
    "    \n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, resize_to).astype(np.float32) / 255.0\n",
    "    \n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, resize_to, interpolation=cv2.INTER_NEAREST)\n",
    "    mask = (mask > 127).astype(np.uint8)\n",
    "    \n",
    "    orig_images.append(img)\n",
    "    gt_masks.append(mask)\n",
    "\n",
    "model.eval()\n",
    "device = next(model.parameters()).device\n",
    "error_maps, all_scores, all_gts = [], [], []\n",
    "\n",
    "for img, mask in zip(orig_images, gt_masks):\n",
    "    x = torch.from_numpy(img.transpose(2, 0, 1)).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model(x)\n",
    "        recon = out[0] if isinstance(out, tuple) else out\n",
    "    recon = recon.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
    "    recon = np.clip(recon, 0, 1)\n",
    "    \n",
    "    err_map = np.abs(img - recon).mean(axis=2)\n",
    "    error_maps.append(err_map)\n",
    "    \n",
    "    all_scores.extend(err_map.flatten())\n",
    "    all_gts.extend(mask.flatten())\n",
    "\n",
    "all_scores = np.array(all_scores)\n",
    "all_gts = np.array(all_gts)\n",
    "\n",
    "thresholds = np.linspace(0, 1, 200)\n",
    "f1s = [f1_score(all_gts, all_scores >= t) for t in thresholds]\n",
    "best_threshold = thresholds[np.argmax(f1s)]\n",
    "print(f\"Best threshold (by F1): {best_threshold:.4f}\")\n",
    "\n",
    "\n",
    "fpr, tpr, _ = roc_curve(all_gts, all_scores)\n",
    "auc = roc_auc_score(all_gts, all_scores)\n",
    "print(f\"AUROC:{auc}\")\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(fpr, tpr, label=f\"AUROC = {auc:.3f}\")\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Pixel-wise ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNdtIAJV4atk5zlkeHnfHym",
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
